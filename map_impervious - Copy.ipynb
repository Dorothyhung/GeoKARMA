{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import rasterio as rio\n",
    "from rasterio import CRS\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.plot import show\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models, layers, utils, backend as K\n",
    "\n",
    "from functions import one_hot_encode, preprocess, binary_classification_preprocess, multiclass_classification_preprocess, nn_regression_preprocess\n",
    "from functions import linear_regression, logistic_regression, decision_tree, random_forest, neural_net\n",
    "from neural_net_functions import DNN_functional, get_compiled_model, dense_block, run_training, neural_net, nn_regression_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads a portion of raster\n",
    "def read_image_chunk(path, xgeo, ygeo, width, height):\n",
    "    with rio.open(path) as ds:\n",
    "        row, col = ds.index(xgeo, ygeo)\n",
    "        data = ds.read(window=rio.windows.Window(col, row, width, height))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads all files and adds each band/window of 200x200 to images array\n",
    "paths = ['data/geoKARMA_h24v13_landsat_2019.tif',\n",
    "    'data/geoKARMA_h24v13_aspect_2019.tif',\n",
    "    'data/geoKARMA_h24v13_dem_2019.tif',\n",
    "    'data/geoKARMA_h24v13_posidex_2019.tif', \n",
    "    'data/geoKARMA_h24v13_wetlands_2019.tif',\n",
    "    'data/geoKARMA_h24v13_impervious_2019.tif']\n",
    "training_dataset = './data/geoKARMA_h24v13_pixelbased_dataset.csv'\n",
    "\n",
    "\n",
    "# opens and read paths into one array images\n",
    "def open_paths():\n",
    "    with rio.open(paths[1]) as src0:\n",
    "        profile = src0.profile\n",
    "\n",
    "    datas = {path.split('_')[-2]: read_image_chunk(path, 1034415, 1364805, 201, 201) for path in paths}\n",
    "    images = pd.DataFrame(np.concatenate([datas[key] for key in ['landsat', 'dem', 'aspect', 'posidex', 'wetlands', 'impervious']]).reshape(11, -1).transpose(), columns=['landsat_1', 'landsat_2', 'landsat_3', 'landsat_4', 'landsat_5', \n",
    "                                                                                                        'landsat_6', 'dem_1', 'aspect_1', 'posidex_1', 'wetlands_1', 'impervious_1'])\n",
    "    print(\"shape in open_paths\", images.shape)\n",
    "    return profile, images\n",
    "\n",
    "# define features based on regression model\n",
    "def get_features(pred_function):\n",
    "    if pred_function == linear_regression:\n",
    "        features = ['landsat_1', 'landsat_2', 'landsat_3', 'landsat_4', 'landsat_5', 'landsat_6',  \n",
    "        'aspect_1_0', 'aspect_1_1', 'aspect_1_2', 'aspect_1_3', 'aspect_1_4',\n",
    "        'aspect_1_5', 'aspect_1_6', 'aspect_1_7', 'aspect_1_8', 'aspect_1_9', \n",
    "        'aspect_1_10', 'aspect_1_11', 'aspect_1_12', 'aspect_1_13', 'aspect_1_14',\n",
    "        'aspect_1_15', 'aspect_1_16', 'aspect_1_17','aspect_1_18', \n",
    "        'wetlands_1_0', 'wetlands_1_2', 'wetlands_1_3', 'wetlands_1_4', \n",
    "        'wetlands_1_5', 'wetlands_1_6', 'wetlands_1_7', 'wetlands_1_8',\n",
    "        'dem_1', 'posidex_1']\n",
    "    if pred_function == logistic_regression:\n",
    "        features = ['landsat_1', 'landsat_2', 'landsat_3', 'landsat_4', 'landsat_5', 'landsat_6']\n",
    "    if pred_function == decision_tree or pred_function == random_forest:\n",
    "        features = ['landsat_1', 'landsat_2', 'landsat_3', 'landsat_4', 'landsat_5', 'landsat_6']\n",
    "\n",
    "    if pred_function == neural_net:\n",
    "        features = ['landsat_1', 'landsat_2', 'landsat_3', 'landsat_4', 'landsat_5', 'landsat_6',  \n",
    "        'aspect_1_0', 'aspect_1_1', 'aspect_1_2', 'aspect_1_3', 'aspect_1_4',\n",
    "        'aspect_1_5', 'aspect_1_6', 'aspect_1_7', 'aspect_1_8', 'aspect_1_9', \n",
    "        'aspect_1_10', 'aspect_1_11', 'aspect_1_12', 'aspect_1_13', 'aspect_1_14',\n",
    "        'aspect_1_15', 'aspect_1_16', 'aspect_1_17','aspect_1_18', \n",
    "        'wetlands_1_0', 'wetlands_1_2', 'wetlands_1_3', 'wetlands_1_4', \n",
    "        'wetlands_1_5', 'wetlands_1_6', 'wetlands_1_7', 'wetlands_1_8',\n",
    "        'dem_1', 'posidex_1', 'NDVI']\n",
    "    return features\n",
    "\n",
    "def get_input_df(pred_function, features):\n",
    "    profile, images = open_paths()\n",
    "    # returns input dataframe holding features\n",
    "    if pred_function == neural_net: data = nn_regression_preprocess(images)[features]\n",
    "    else: data = preprocess(images)[features]\n",
    "    print(\"shape in get_input_df\", data.shape)\n",
    "    return profile, data\n",
    "\n",
    "def get_predictions(input_df, model):\n",
    "    #df = input_df.apply(lambda row: model.predict(row.values[None])[0], axis = 1)\n",
    "    df = model.predict_on_batch(input_df)\n",
    "    return df\n",
    "\n",
    "def write_raster(profile, array, new_name):\n",
    "    with rio.open(new_name, 'w', **profile) as output:\n",
    "        output.write(array)\n",
    "\n",
    "def map_impervious(pred_function, new_name):\n",
    "    # define features and input\n",
    "    features = get_features(pred_function)\n",
    "    profile, df = get_input_df(pred_function, features)\n",
    "\n",
    "    # gets the regression model trained on full csv dataset\n",
    "    #get predictions for input\n",
    "    if pred_function == neural_net:\n",
    "        model = tf.keras.models.load_model(\"./data/model.h5\", compile=False)\n",
    "        impervious_df = model.predict_on_batch(df)\n",
    "    elif pred_function == decision_tree:\n",
    "        impervious_df = get_predictions(df, pred_function(training_dataset, 5))\n",
    "    else:\n",
    "        impervious_df = get_predictions(df, pred_function(training_dataset))\n",
    "\n",
    "    # reshapes output into 200x200 array\n",
    "    impervious_output = np.array(impervious_df).reshape(1, 200, 200)\n",
    "    if pred_function == neural_net:\n",
    "        impervious_output = np.transpose(impervious_output, (0,2,1))\n",
    "    \n",
    "    #write new raster\n",
    "    write_raster(profile, impervious_output, new_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for model: linear_regression, logistic_regression, decision_tree, neural_net\n",
    "\n",
    "map_impervious(logistic_regression, 'logistic_test2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = rio.open('logistic_test2.tif')\n",
    "show(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
